{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "import chromadb\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# from kiwipiepy import Kiwi\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "240717\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"240717\") #set_enable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_LANSMITH_PROJECTNAME = \"240717\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI()\n",
    "# # 간단하게 API 텍스트 호출\n",
    "# llm.invoke(\"LangSmith로 Testing과 Evaluation을 어떻게 할 수 있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=12_files_openai_3072), Collection(name=csv_files_openai_3072)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 컬렉션 생성/연결하기\n",
    "import chromadb\n",
    "client = chromadb.PersistentClient('chroma/')\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cauhike/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "class MultiCollectionRetriever:\n",
    "    def __init__(self, client, collection_names, embedding_function, search_kwargs={\"k\": 2}):\n",
    "        self.collections = [\n",
    "            Chroma(client=client, collection_name=name, embedding_function=embedding_function)\n",
    "            for name in collection_names\n",
    "        ]\n",
    "        self.search_kwargs = search_kwargs\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        results = []\n",
    "        for collection in self.collections:\n",
    "            # 각 컬렉션에서 유사도 검색 수행\n",
    "            documents_with_scores = collection.similarity_search_with_score(query, **self.search_kwargs)\n",
    "            results.extend(documents_with_scores)\n",
    "        \n",
    "        # 유사도 점수를 기준으로 결과 정렬 (score가 높을수록 유사도가 높음)\n",
    "        results.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "        documents = [(doc, score) for doc, score in results]\n",
    "        return documents\n",
    "\n",
    "# 사용 예시\n",
    "collection_names = [\"csv_files_openai_3072\", \"12_files_openai_3072\"]\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large') \n",
    "multi_retriever = MultiCollectionRetriever(client, collection_names, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************KD0r. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m사물주소와 관련된 체계가 존재하는가?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m top_results \u001b[38;5;241m=\u001b[39m results[:\u001b[38;5;241m5\u001b[39m]  \u001b[38;5;66;03m# 상위 5개 결과 선택\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 최종 결과 출력\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for doc, score in top_results:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     print(f\"Document: {doc.page_content}, Score: {score}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mMultiCollectionRetriever.retrieve\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collection \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollections:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 각 컬렉션에서 유사도 검색 수행\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     documents_with_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(documents_with_scores)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 유사도 점수를 기준으로 결과 정렬 (score가 높을수록 유사도가 높음)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:438\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    431\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[1;32m    432\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    436\u001b[0m     )\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    440\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39m[query_embedding],\n\u001b[1;32m    441\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    445\u001b[0m     )\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:697\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:668\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:494\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    492\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 494\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    500\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:116\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rag/.venv/lib/python3.11/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************KD0r. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "query = \"사물주소와 관련된 체계가 존재하는가?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "\n",
    "# 최종 결과 출력\n",
    "# for doc, score in top_results:\n",
    "#     print(f\"Document: {doc.page_content}, Score: {score}\")\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data/final/김지영-사물주소 부여 체계 분석 및 정책제언-2023.txt'}, page_content='2. 사물주소 부여 체계 분석\\n사물주소(address of things, AOT)와 관련된 체계가 정리된 자료가 없어 「도로명주소법」 등 관련 법령을 바탕으로 데이터 관점에서 그 체계를 분석하고자 한다. 이를 위해서 ISO 19160-1에 제시되어 있는 주소 개념 모델에서 주소와 연관이나 집합관계에 있는 클래스 (class)를 중심으로 분석하였다(Table 1). 주소(address) 는 하나 이상의 주소 구성요소(AddressComponent)와 집합관계이다. 주소 구성요소 값은 라벨(label)로 주소를 구성하는 객체를 문자로 표현한 것을 의미한다. 즉 도로를 도로명이라는 문자로 표현한 것이다. 또한 주소는 건물등과 같이 주소가 할당되는 객체를 의미하는 주소 부여 대상(AddressableObject)과 상호 연관되어 있으며, 동일한 주소 부여 대상을 명확하게 식별하기 위하여 주소 별칭(AddressAlias)과 연관되어 있다(Kim and Yang, 2020).'),\n",
       "  0.7974888682365417),\n",
       " (Document(metadata={'source': 'data/final/ISO 19160-1-2015 개념모델에 대한 분석과 이해.txt'}, page_content='한국의 주소체계는 2014년에 지번주소에서 도로명주소로 전면 개편되었고, 이후 도로명주소, 사물주소, 공간주소 등 다양한 유형이 새롭게 개발되며 주소의 부여 범위를 건축물을 넘어 사물, 해안·해양으로 점차 확대하고 있다[7]. 한국의 주소는 도로명주소법을 법률적 근거로 국가주소정보시스템을 통해 관리되고, 주소정보누리집(도로명주소 안내시스템)과 주소기반산업지원서비스를 통해 공공·민간에서 주소를 활용 하고 있다. 행정안전부는 제1차 주소정보 활용 기본계획 (2022~2026)을 시행하며 주소를 ‘현실과 가상세계를 연결하는 매개체’로 정의하고 주소의 데이터 가치를 확대하고 있다. 데이터 관점에서 주소는 행정구역, 도로, 공간과 같은 다양한 구성요소의 결합된 특성을 갖고 동시에 서로 다른 도메인의 상세정보에 대한 참조기능을 갖는다. 이런 맥락에서 주소가 다양한 데이터와 연계 또는 통합되려면 데이터 표준에 대한 고려가 반드시 필요하다. 그러나, 한국 주소체계의 표준에 대한 논의는 위치,'),\n",
       "  0.8069764375686646),\n",
       " (Document(metadata={'row': 228, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 50\\n필수여부: 필수\\n준용여부: 준용\\n용어명: 사물주소\\n정의: 도로명과 기초번호를 활용하여 건물등에 해당하지 아니하는 시설물의 위치를 특정하는 정보\\n선정근거_출처: 도로명주소법\\n선정근거_세부내용: 2조\\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 주소정보의 하위 개념으로 다중이 이용하는 시설물로 행정안전부장관이 고시한 시설물에 대하여 도로명과 건물번호, 사물번호와 사물유형으로 표현하는 주소정보\\n유사용어:'),\n",
       "  0.8882288932800293),\n",
       " (Document(metadata={'row': 230, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 171\\n필수여부: 필수\\n준용여부: 미준용\\n용어명: 사물주소(건물밖)참조체계\\n정의: 도로명방식을 참조하는 건물 밖 사물주소 참조체계를 말함\\n선정근거_출처: 주소정보기본도 작성·관리 규정\\n선정근거_세부내용: \\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 주소참조체계의 하위 유형으로, 건물 외부에 존재하는 사물의 주소를 부여할 때 사용되는 참조체계\\n유사용어:'),\n",
       "  0.9153549671173096)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [(doc, score) for doc, score in top_results]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(metadata={'source': 'data/final/김지영-사물주소 부여 체계 분석 및 정책제언-2023.txt'}, page_content='2. 사물주소 부여 체계 분석\\n사물주소(address of things, AOT)와 관련된 체계가 정리된 자료가 없어 「도로명주소법」 등 관련 법령을 바탕으로 데이터 관점에서 그 체계를 분석하고자 한다. 이를 위해서 ISO 19160-1에 제시되어 있는 주소 개념 모델에서 주소와 연관이나 집합관계에 있는 클래스 (class)를 중심으로 분석하였다(Table 1). 주소(address) 는 하나 이상의 주소 구성요소(AddressComponent)와 집합관계이다. 주소 구성요소 값은 라벨(label)로 주소를 구성하는 객체를 문자로 표현한 것을 의미한다. 즉 도로를 도로명이라는 문자로 표현한 것이다. 또한 주소는 건물등과 같이 주소가 할당되는 객체를 의미하는 주소 부여 대상(AddressableObject)과 상호 연관되어 있으며, 동일한 주소 부여 대상을 명확하게 식별하기 위하여 주소 별칭(AddressAlias)과 연관되어 있다(Kim and Yang, 2020).'),\n",
       " 0.7974888682365417)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/final/김지영-사물주소 부여 체계 분석 및 정책제언-2023.txt'}, page_content='2. 사물주소 부여 체계 분석\\n사물주소(address of things, AOT)와 관련된 체계가 정리된 자료가 없어 「도로명주소법」 등 관련 법령을 바탕으로 데이터 관점에서 그 체계를 분석하고자 한다. 이를 위해서 ISO 19160-1에 제시되어 있는 주소 개념 모델에서 주소와 연관이나 집합관계에 있는 클래스 (class)를 중심으로 분석하였다(Table 1). 주소(address) 는 하나 이상의 주소 구성요소(AddressComponent)와 집합관계이다. 주소 구성요소 값은 라벨(label)로 주소를 구성하는 객체를 문자로 표현한 것을 의미한다. 즉 도로를 도로명이라는 문자로 표현한 것이다. 또한 주소는 건물등과 같이 주소가 할당되는 객체를 의미하는 주소 부여 대상(AddressableObject)과 상호 연관되어 있으며, 동일한 주소 부여 대상을 명확하게 식별하기 위하여 주소 별칭(AddressAlias)과 연관되어 있다(Kim and Yang, 2020).'),\n",
       " Document(metadata={'source': 'data/final/ISO 19160-1-2015 개념모델에 대한 분석과 이해.txt'}, page_content='한국의 주소체계는 2014년에 지번주소에서 도로명주소로 전면 개편되었고, 이후 도로명주소, 사물주소, 공간주소 등 다양한 유형이 새롭게 개발되며 주소의 부여 범위를 건축물을 넘어 사물, 해안·해양으로 점차 확대하고 있다[7]. 한국의 주소는 도로명주소법을 법률적 근거로 국가주소정보시스템을 통해 관리되고, 주소정보누리집(도로명주소 안내시스템)과 주소기반산업지원서비스를 통해 공공·민간에서 주소를 활용 하고 있다. 행정안전부는 제1차 주소정보 활용 기본계획 (2022~2026)을 시행하며 주소를 ‘현실과 가상세계를 연결하는 매개체’로 정의하고 주소의 데이터 가치를 확대하고 있다. 데이터 관점에서 주소는 행정구역, 도로, 공간과 같은 다양한 구성요소의 결합된 특성을 갖고 동시에 서로 다른 도메인의 상세정보에 대한 참조기능을 갖는다. 이런 맥락에서 주소가 다양한 데이터와 연계 또는 통합되려면 데이터 표준에 대한 고려가 반드시 필요하다. 그러나, 한국 주소체계의 표준에 대한 논의는 위치,'),\n",
       " Document(metadata={'row': 228, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 50\\n필수여부: 필수\\n준용여부: 준용\\n용어명: 사물주소\\n정의: 도로명과 기초번호를 활용하여 건물등에 해당하지 아니하는 시설물의 위치를 특정하는 정보\\n선정근거_출처: 도로명주소법\\n선정근거_세부내용: 2조\\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 주소정보의 하위 개념으로 다중이 이용하는 시설물로 행정안전부장관이 고시한 시설물에 대하여 도로명과 건물번호, 사물번호와 사물유형으로 표현하는 주소정보\\n유사용어:'),\n",
       " Document(metadata={'row': 230, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 171\\n필수여부: 필수\\n준용여부: 미준용\\n용어명: 사물주소(건물밖)참조체계\\n정의: 도로명방식을 참조하는 건물 밖 사물주소 참조체계를 말함\\n선정근거_출처: 주소정보기본도 작성·관리 규정\\n선정근거_세부내용: \\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 주소참조체계의 하위 유형으로, 건물 외부에 존재하는 사물의 주소를 부여할 때 사용되는 참조체계\\n유사용어:')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"사물주소와 관련된 체계가 존재하는가?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "\n",
    "# 최종 결과 출력\n",
    "# for doc, score in top_results:\n",
    "#     print(f\"Document: {doc.page_content}, Score: {score}\")\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 11, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 255\\n필수여부: 선택\\n준용여부: 미준용\\n용어명: 가상도로구간\\n정의: 개설이 예상되는 도로에 대한 도로구간\\n선정근거_출처: 주소정보기본도 작성·관리 규정\\n선정근거_세부내용: 11조\\n주소지식모델 포함여부: 미포함\\n주소지식모델정의: \\n유사용어:'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20240611110832Z00'00'\", 'creator': '', 'file_path': 'data/final/[1018] 주소정보_업무편람_최종(하이퍼링크).pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240611110832Z00'00'\", 'page': 285, 'producer': 'macOS Version 14.5 (Build 23F79) Quartz PDFContext', 'source': 'data/final/[1018] 주소정보_업무편람_최종(하이퍼링크).pdf', 'subject': '', 'title': '', 'total_pages': 525, 'trapped': ''}, page_content='■  ■  ■\\n주소정보 업무편람\\n292\\n가상도로구간\\n5) \\n가상도로구간은 두 개 이상의 지상도로를 연결하는 도로의 개설이 예상되어 하\\n○ \\n나의 도로구간으로 설정한 경우 도로의 개설이 예상되는 범위를 선형으로 작성\\n가상기초간격\\n6) \\n가상기초간격은 가상도로구간을 대상으로 도로구간의 기초간격 작성 방법에 \\n○ \\n따라 작성\\n그림 \\n가상도로구간과 가상기초간격\\n[\\n4-11] \\n연결선\\n7) \\n가\\n일반원칙\\n) \\n도로구간은 다음과 같이 분류하여 서로 연결되도록 선형으로 작성\\n○ \\n기초간격과 건물등 또는 건물군의 출입구\\n- \\n기초간격과 사물의 사물번호기준점\\n- \\n실내 이동경로 기초간격과 층호의 출입구\\n- \\n·\\n실내 이동경로 기초간격과 사물의 사물번호기준점\\n- \\n단지내 도로와 동 출입구\\n- \\n나\\n세부방법\\n) \\n연결 대상 간에는 통행을 고려하여 최단거리로 작성\\n○')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"가상도로구간이 무슨 의미야?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 496, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 246\\n필수여부: 필수\\n준용여부: 미준용\\n용어명: 행정구역\\n정의: 법률에 정해진 지방자치단체의 구역(법정구역)이나 조례로 정해진 자치구가 아닌 구와 읍ㆍ면ㆍ동 등의 구역\\n선정근거_출처: 지방자치법\\n선정근거_세부내용: 5조\\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 법률에 정해진 지방자치단체의 구역(법정구역)이나 조례로 정해진 자치구가 아닌 구와 읍ㆍ면ㆍ동 등의 구역\\n유사용어:'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20240611110832Z00'00'\", 'creator': '', 'file_path': 'data/final/[1018] 주소정보_업무편람_최종(하이퍼링크).pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240611110832Z00'00'\", 'page': 31, 'producer': 'macOS Version 14.5 (Build 23F79) Quartz PDFContext', 'source': 'data/final/[1018] 주소정보_업무편람_최종(하이퍼링크).pdf', 'subject': '', 'title': '', 'total_pages': 525, 'trapped': ''}, page_content='·\\n·\\n·\\n. \\n, \\n○ \\n법에 따라 부여된 사업지역의 명칭을 말함\\n5) 건물등 관할구역\\n시도시군자치구행정구읍면의 행정구역을 말함단행정구역 미결정 지역\\n·\\n, \\n·\\n·\\n, \\n·\\n·\\n. \\n, \\n○ \\n에서는 이 법에 따라 부여된 사업지역의 명칭을 말함\\n6) 공공기관의 장\\n국가기관\\n지방자치단체\\n, \\n○ \\n공공기관의 운영에 관한 법률에 따른 공공기관\\n○ 「\\n」')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"행정구역을 법률로 정한걸 뭐라고 해?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/final/chapter-3-3.md'}, page_content='도로명은 시군구코드와 도로명번호를 PK로 사용한다. 도로명번호 7자리는 지자체마다 관리하는 코드로, 고유하지 않다. 따라서, 시군구코드와 도로명번호를 조합한 코드(도로명코드)를 통해 도로명을 식별한다. 하지만, 데이터에 따라 도로명번호(7자리)와 도로명코드(12자리)의 용어가 혼용되므로 자릿수에 주의해야 한다.\\n\\n도로명 데이터에서 사용하는 읍면동일련번호는 하나의 도로가 지나는 읍면동을 구분하기 위해 임의로 부여한 일련번호다. 도로명 데이터에서만 사용되며 읍면동코드와 다른 의미다.\\n\\n도로명 (전체분) 예시'),\n",
       " Document(metadata={'row': 133, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 33\\n필수여부: 필수\\n준용여부: 준용\\n용어명: 도로명\\n정의: 도로구간마다 부여된 이름\\n선정근거_출처: 도로명주소법\\n선정근거_세부내용: 2조\\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 도로참조체계를 따르는 도로명주소(동)의 주소구성요소 중의 하나로 도로구간마다 부여된 이름\\n유사용어:')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"도로명을 구분하는 코드가 존재하는가?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 30, 'source': 'data/final/김지영-사물주소 부여 체계 분석 및 정책제언-2023.txt'}, page_content='사물주소 부여 체계 분석 및 정책제언: 2.1.3 AddressAlias'),\n",
       " Document(metadata={'row': 145, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 307\\n필수여부: 선택\\n준용여부: 미준용\\n용어명: 도로명주소전환\\n정의: 지번과 같이 도로명이 아닌 식별자체계를 도로명주소체계로 전환하는 것\\n선정근거_출처: 주소정보 전산체계 운영규정\\n선정근거_세부내용: 10조\\n주소지식모델 포함여부: 미포함\\n주소지식모델정의: \\n유사용어:')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"AddressAlias는 언제 사용하는지?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data/final/도로명주소법.txt'}, page_content='도로명주소법\\n[시행 2021. 6. 9.] [법률 제17574호, 2020. 12. 8., 전부개정]\\n행정안전부(주소생활공간과) 044-205-3567\\n\\n제1조(목적) 이 법은 도로명주소, 국가기초구역, 국가지점번호 및 사물주소의 표기ㆍ사용ㆍ관리ㆍ활용 등에 관한 사항을 규정함으로써 국민의 생활안전과 편의를 도모하고 관련 산업의 지원을 통하여 국가경쟁력 강화에 이바지함을 목적으로 한다.'),\n",
       "  0.9909842610359192),\n",
       " (Document(metadata={'source': 'data/final/도로명주소법.txt'}, page_content='도로명주소법\\n[시행 2021. 6. 9.] [법률 제17574호, 2020. 12. 8., 전부개정]\\n행정안전부(주소생활공간과) 044-205-3567\\n\\n제1조(목적) 이 법은 도로명주소, 국가기초구역, 국가지점번호 및 사물주소의 표기ㆍ사용ㆍ관리ㆍ활용 등에 관한 사항을 규정함으로써 국민의 생활안전과 편의를 도모하고 관련 산업의 지원을 통하여 국가경쟁력 강화에 이바지함을 목적으로 한다.'),\n",
       "  0.9928990602493286),\n",
       " (Document(metadata={'row': 395, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 77\\n필수여부: 필수\\n준용여부: 준용\\n용어명: 주소정책\\n정의: 국민의 생활안전과 편의를 도모하고 관련 산업의 지원을 통하여 국가경쟁력 강화에 이바지하기 위한 도로명주소의 목적을 실현하기 위한 방책들\\n선정근거_출처: 도로명주소법\\n선정근거_세부내용: 1조\\n주소지식모델 포함여부: 미포함\\n주소지식모델정의: \\n유사용어:'),\n",
       "  1.030405879020691),\n",
       " (Document(metadata={'row': 57, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 9\\n필수여부: 필수\\n준용여부: 준용\\n용어명: 공보등\\n정의: 주소정보에 관한 사항을 알리는 홈페이지 또는 그 밖의 전달매체\\n선정근거_출처: 도로명주소법 시행령\\n선정근거_세부내용: 10조\\n주소지식모델 포함여부: 미포함\\n주소지식모델정의: \\n유사용어:'),\n",
       "  1.102662205696106)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"도로명주소의 시행 목적이 뭐야?\"\n",
    "results = multi_retriever.retrieve(query)\n",
    "top_results = results[:5]  # 상위 5개 결과 선택\n",
    "top_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "# GraphState 상태를 저장하는 용도로 사용합니다.\n",
    "class GraphState(TypedDict):\n",
    "    question: str  # 질문\n",
    "    context: str  # 문서의 검색 결과\n",
    "    answer: str  # llm이 생성한 답변\n",
    "    relevance: str  # 답변의 문서에 대한 관련성 (groundness check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NODE] Vector Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # Question 에 대한 문서 검색을 retriever 로 수행합니다.\n",
    "    retrieved_docs = multi_retriever.retrieve(state[\"question\"])\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(context=retrieved_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/final/양성철-도로명주소의 주소정보기반대상 등록 제도 개선 연구.txt'}, page_content='2. 건물번호 부여 및 등록 기준 \\n2.1. 법령상 건물번호 부여 기준'),\n",
       " Document(metadata={'row': 23, 'source': 'data/csv/주소용어최종정리_1123 - 업데이트_231123.csv'}, page_content='번호: 5\\n필수여부: 필수\\n준용여부: 준용\\n용어명: 건물번호\\n정의: 도로구간의 기초번호를 기준으로 건물등과 건물군에 부여된 번호\\n선정근거_출처: 도로명주소법\\n선정근거_세부내용: 2조\\n주소지식모델 포함여부: 포함\\n주소지식모델정의: 실내경로참조체계를 따르는 사물주소(안) 참조체계의 주소구성요소 중의 하나로 도로구간의 기초번호를 기준으로 건물등과 건물군에 부여된 번호\\n유사용어:')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_retriever.retrieve(\"건물번호는 어떤 규칙으로 부여돼?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NODE] Groundness Checker\n",
    "\n",
    "* gpt4o\n",
    "* question과 retrieve한 context간을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain을 사용하여 답변을 생성합니다.\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "def relevance_message(context, question):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"\n",
    "            너는 Query와 Document를 비교해서 ['grounded', 'notGrounded', 'notSure'] 셋 중 하나의 라벨을 출력하는 모델이야.\n",
    "\n",
    "            'grounded': Compare the Query and the Document. If the Document includes content that can be used to generate an answer to the Query, output the label 'grounded'.\n",
    "            'notGrounded': Compare the Query and the Document. If the Document not includes content that can be used to generate an answer to the Query, output the label 'notGrounded'.\n",
    "            'notSure': Compare the Query and the Document. If you cannot determine whether the Document includes content that can be used to generate an answer to the Query, output the label .notSure'.\n",
    "            \n",
    "            너의 출력은 반드시 'grounded', 'notGrounded', 'notSure' 중 하나여야 해. 띄어쓰기나 대소문자 구분 등 다른 형식이나 추가적인 설명 없이 오직 하나의 라벨만 출력해줘.\n",
    "        \"\"\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            [Document]\n",
    "            {context}\n",
    "\n",
    "            [Query]\n",
    "            {question}\n",
    "        \"\"\"),\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    messages = relevance_message(state[\"context\"], state[\"question\"])\n",
    "    response = chat.invoke(messages)\n",
    "    return GraphState(\n",
    "        relevance=response.content,\n",
    "        context=state[\"context\"],\n",
    "        answer=state[\"answer\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    if state[\"relevance\"] == \"grounded\":\n",
    "        return \"관련성 O\"\n",
    "    elif state[\"relevance\"] == \"notGrounded\":\n",
    "        return \"관련성 X\"\n",
    "    elif state[\"relevance\"] == \"notSure\":\n",
    "        return \"확인불가\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NODE] llm answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain을 사용하여 답변을 생성합니다.\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "def message(context, question):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"\n",
    "            너는 Document의 정보를 반드시 활용해서 답변을 생성하는 챗봇이야. \n",
    "            이때, 답변은 Document에 정보가 있을 수도 있고, 없을 수도 있어. \n",
    "            Document의 정보로 답변을 생성할 수 있는 경우 해당 정보를 활용하고, 만약 Document의 정보로 답변을 유추조차 할 수 없는 경우, Document를 참고하지 말고 그냥 너가 생각한 답변을 생성해줘.\n",
    "            주소와 관련된 질문인 경우 최대한 Document의 답변을 기반을 참고해주고, 그렇지 않은 경우 그냥 너의 지식을 활용해줘.\n",
    "            답변에는 Document라는 단어를 사용하지 말아줘.\n",
    "            \n",
    "            답변의 끝에는 출처의 정보를 기입하는데, 출처는 Document의 'context'에 metadata의 'source'에 파일경로로 기입되어 있어. pdf, csv, md 등의 파일 이름으로만 출처를 기입해주면 돼.\n",
    "            만약 여러개의 출처가 기입되어 있는 경우 모두 알려주고, 중복되는 경우 하나만 기입해줘.\n",
    "            이때 파일명의 확장자(pdf, csv, md 등)는 기입하지 않아도 돼.\n",
    "        \"\"\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            [Document]\n",
    "            {context}\n",
    "\n",
    "            [Query]\n",
    "            {question}\n",
    "        \"\"\"),\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    messages = message(state[\"context\"], state[\"question\"])\n",
    "    response = chat.invoke(messages)\n",
    "    return GraphState(\n",
    "        answer=response.content,\n",
    "        context=state[\"context\"],\n",
    "        question=state[\"question\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Relations (with nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드들을 정의합니다.\n",
    "workflow.add_node(\"retrieve\", retrieve_document)  # 답변을 검색해오는 노드를 추가합니다.\n",
    "workflow.add_node(\"llm_answer\", llm_answer)  # 답변을 생성하는 노드를 추가합니다.\n",
    "workflow.add_node(\"relevance_check\", relevance_check)  # 답변의 문서에 대한 관련성 체크 노드를 추가합니다.\n",
    "\n",
    "# 각 노드들을 연결합니다.\n",
    "# workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "# workflow.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 -> 관련성 체크\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"relevance_check\")  # 검색 -> 답변\\\n",
    "\n",
    "# 조건부 엣지를 추가합니다.\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"관련성 O\": \"llm_answer\",  # 관련성이 있으면 종료합니다.\n",
    "        \"관련성 X\": \"llm_answer\",  # 관련성이 없으면 다시 답변을 생성합니다.\n",
    "        \"확인불가\": \"llm_answer\",  # 관련성 체크 결과가 모호하다면 다시 답변을 생성합니다.\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"llm_answer\", END)  # 답변 -> 종료\n",
    "\n",
    "# 시작점을 설정합니다.\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 기록을 위한 메모리 저장소를 설정합니다.\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프를 컴파일합니다.\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(app.get_graph(xray=True).draw_mermaid_png())\n",
    "    )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "except:\n",
    "    # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t 사물주소와 관련된 체계가 존재하는가?\n",
      "Answer: \t 사물주소와 관련된 체계는 존재합니다. 관련 법령인 「도로명주소법」을 바탕으로 분석된 체계가 있으며, ISO 19160-1에 제시된 주소 개념 모델에서 주소와 연관된 클래스들을 중심으로 체계를 구성하고 있습니다. 사물주소는 도로명과 기초번호를 활용하여 건물 등이 아닌 시설물의 위치를 특정하는 정보를 의미합니다.\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"사물주소와 관련된 체계가 존재하는가?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t 네이버 지오코딩 API를 활용하는 방법은?\n",
      "Answer: \t 네이버 지오코딩 API를 활용하려면 다음과 같은 절차를 따르시면 됩니다:\n",
      "\n",
      "1. **네이버 클라우드 플랫폼에 접속**:\n",
      "   - 네이버 클라우드 플랫폼에 로그인합니다.\n",
      "   - 화면 상단의 콘솔 버튼을 클릭합니다.\n",
      "\n",
      "2. **API Key 발급**:\n",
      "   - API를 활용하기 위해 API Key를 발급받아야 합니다.\n",
      "   - 네이버 지오코딩 API Key는 네이버 클라우드 플랫폼에서 발급받을 수 있습니다.\n",
      "\n",
      "3. **API 요청 구성**:\n",
      "   - API 요청을 위해 필요한 형식에 맞춰 요청 URL을 작성해야 합니다.\n",
      "   - 요청 헤더에는 발급받은 API Key와 아이디 값을 입력합니다.\n",
      "\n",
      "4. **예시 코드**:\n",
      "   - 아래는 간단한 API 요청 예시 코드입니다.\n",
      "\n",
      "   ```python\n",
      "   import requests as re\n",
      "   import json\n",
      "   \n",
      "   # 요청 헤더에 API 키와 아이디 값 입력\n",
      "   headers = {\n",
      "       \"X-NCP-APIGW-API-KEY-ID\": \"YOUR_API_ID\",\n",
      "       \"X-NCP-APIGW-API-KEY\": \"YOUR_API_SECRET\"\n",
      "   }\n",
      "   \n",
      "   # 파라미터에는 검색할 주소 입력\n",
      "   params = {\n",
      "       \"query\": \"서울특별시 동작구 흑석로 84\",\n",
      "       \"output\": \"json\"\n",
      "   }\n",
      "   \n",
      "   # 정보 요청할 URL\n",
      "   url = \"https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode\"\n",
      "   \n",
      "   # API 호출\n",
      "   response = re.get(url, headers=headers, params=params)\n",
      "   data = response.json()\n",
      "   \n",
      "   # 결과 출력\n",
      "   print(json.dumps(data, indent=4, ensure_ascii=False))\n",
      "   ```\n",
      "\n",
      "위의 코드를 통해 네이버 지오코딩 API를 호출하여 주소를 좌표로 변환할 수 있습니다. 필요한 API Key와 기타 설정 값들을 정확히 입력해야 정상적으로 작동합니다.\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"네이버 지오코딩 API를 활용하는 방법은?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t 실내 이동경로 구간을 작성하는 방법을 알려줘\n",
      "Answer: \t 실내 이동경로 구간을 작성하는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **일반원칙**:\n",
      "   - 실내 이동경로 구간은 사람의 통행을 중심으로 층 단위로 작성해야 합니다.\n",
      "   - 작성 단위마다 도로명, 건물번호, 동번호 등이 없는 경우 생략하고 층수를 함께 등록합니다.\n",
      "   - 실내 이동경로 구간은 부여가 예상되는 상세주소 출입구 또는 사물번호 기준점을 모두 연결 가능하도록 작성합니다.\n",
      "   - 건물 등의 출입구 및 내부의 수직연결점(층 간 이동과 연결되도록)과 연결되도록 작성합니다.\n",
      "\n",
      "2. **세부기준**:\n",
      "   - 하나의 층에 수직연결점이 2개 이상 있고 각 수직연결점을 주로 이용하는 상세주소 또는 사물주소 부여대상이 있는 경우, 2개 이상의 실내 이동경로 구간을 설정하고 서로 연결되도록 작성합니다.\n",
      "   - 하나의 층이 연결되지 않는 두 개의 공간으로 분리되어 각 공간에 수직연결점이 있는 경우, 각 공간에 실내 이동경로 구간을 설정합니다.\n",
      "\n",
      "3. **작성 예시**:\n",
      "   - 실내 이동경로 구간은 사람의 통행을 중심으로 층 단위의 선형으로 작성합니다.\n",
      "   - 시작지점은 사람의 이용이 많은 수직연결점을 기준으로 합니다.\n",
      "   - 타원형의 경우에는 시계 반대 방향으로 실내 이동경로 구간을 설정합니다.\n",
      "\n",
      "이와 같은 방법으로 실내 이동경로 구간을 작성하여야 합니다.\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"실내 이동경로 구간을 작성하는 방법을 알려줘\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t 도로명주소의 시행 목적이 뭐야?\n",
      "Answer: \t \n",
      "도로명주소법의 목적은 도로명주소, 국가기초구역, 국가지점번호 및 사물주소의 표기, 사용, 관리, 활용 등에 관한 사항을 규정함으로써 국민의 생활안전과 편의를 도모하고 관련 산업의 지원을 통하여 국가경쟁력 강화에 이바지하는 것입니다.\n",
      "\n",
      "출처: 도로명주소법.txt\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"도로명주소의 시행 목적이 뭐야?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t 주소정보의 개념 재정립이 필요한 이유가 뭐야?\n",
      "Answer: \t 주소정보의 개념을 재정립하는 이유는 크게 두 가지입니다. 첫째, 2014년 도로명주소 전면 시행 이후 4차 산업혁명으로 인한 사회의 급격한 변화에 대응하기 위해서입니다. 둘째, 공법상 주소가 아닌 정보로서의 주소에 대한 관심과 필요성이 증가함에 따라, 다양한 연구에서 제시된 새로운 개념을 체계적으로 정리할 필요가 있기 때문입니다. 이러한 재정립은 도로명주소법의 개정을 앞두고 미래를 대비한 정교한 주소체계를 확립하는 데에 중요한 기반이 됩니다.\n",
      "\n",
      "출처: 주소체계 고도화에 따른 주소정보 개념 정립 연구.pdf\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"주소정보의 개념 재정립이 필요한 이유가 뭐야?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t AddressAlias의 의미와 활용 방법을 알려줘\n",
      "Answer: \t AddressAlias는 주소를 명확하게 식별하기 위한 대체 표현 또는 별칭을 의미합니다. 이는 언어나 문화권에 따른 표기(localeAlias), 주소의 생애주기에 따라 변화된 주소 표기(lifecycleAlias), 비공식적 또는 구어체 표기(colloquialAlias), 그리고 AddressClass의 표기(classAlias) 등에 적용될 수 있습니다. 여러 별칭이 존재할 경우, 선호도(preferenceLevel)에 따라 우선순위를 나타낼 수 있습니다. 예를 들어, 한국의 주소 클래스는 도로명 주소와 지번 주소로 구분될 수 있습니다.\n",
      "\n",
      "출처: ISO 19160-1-2015 개념모델에 대한 분석과 이해, 김지영-양성청-도로명주소법 개정에 대비한 표준기반 사물주소 정의\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"AddressAlias의 의미와 활용 방법을 알려줘\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data/final/ISO 19160-1-2015 개념모델에 대한 분석과 이해.txt'}, page_content='AddressAlias 클래스는 주소를 명확하게 식별하기 위한 대체 표현 또는 별칭을 표현한다. 이 클래스는 언어나 문화권 에 따른 표기(localeAlias), 주소의 생애주기에 따라 변화된 주소 표기(lifecycleAlias), 주소의 비공식적 또는 구어체에 표기(colloquialAlias), AddressClass의 표기(classAlias) 에 적용할 수 있다. AddressClass 클래스는 동일한 주소구 성요소, 관계, 의미를 공유하는 주소 집합을 의미하고, 주소의 유형에따라확장될수있다. 예를들어, 한국의 주소클래스는 도로명주소와 지번주소로 구분할 수 있다. 별칭이 여러 개인 경우, 선호도(preferenceLevel)에 따라 우선순위를 나타 낼 수 있다.'),\n",
       "  0.6787415615843314),\n",
       " (Document(metadata={'source': 'data/final/김지영-양성청-도로명주소법 개정에 대비한 표준기반 사물주소 정의.txt'}, page_content='또한 동일한 주소부여대상을 명확하게 확인하기 위하여 주소들은 AddressAlias(주소 별칭)으로 참조된다. 표준에서는 두 개의 도로 모퉁이에 접하는 하나의 건물 이 각 도로마다 출입구가 있어 출입구마다 주소가 부여된 건물을 예로 들고 있다.'),\n",
       "  0.822756826877594)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/final/주소정보_업무편람_최종(하이퍼링크).pdf'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['context'][1][0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t python에서 pandas를 활용하여 csv 파일을 읽는 방법과 예시를 알려줘\n",
      "Answer: \t Python에서 pandas 라이브러리를 사용하여 CSV 파일을 읽는 방법은 매우 간단합니다. pandas의 `read_csv` 함수를 사용하면 됩니다. 아래는 예시 코드입니다:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# CSV 파일 읽기\n",
      "df = pd.read_csv('sample.csv')\n",
      "\n",
      "# 데이터 형태 파악하기\n",
      "print(df.shape)\n",
      "\n",
      "# 데이터의 첫 5행 출력\n",
      "print(df.head(5))\n",
      "```\n",
      "\n",
      "위 코드에서는 `sample.csv` 파일을 읽어와 데이터프레임 `df`에 저장합니다. 그런 다음, `df.shape`을 사용하여 데이터의 형태(행과 열의 수)를 출력하고, `df.head(5)`을 사용하여 데이터의 첫 5행을 출력합니다.\n",
      "\n",
      "출처: chapter-7-6, chapter-4-5\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"python에서 pandas를 활용하여 csv 파일을 읽는 방법과 예시를 알려줘\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t 미키마우스는 누가 만들었어?\n",
      "Answer: \t 미키마우스는 월트 디즈니와 애브 아이웍스가 공동으로 만든 캐릭터입니다. 미키마우스는 1928년에 처음 등장했습니다.\n",
      "Relevance: \t notGrounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"미키마우스는 누가 만들었어?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t KPOP 가수 5명만 말해줘\n",
      "Answer: \t KPOP 가수 5명은 다음과 같습니다:\n",
      "\n",
      "1. BTS (방탄소년단)\n",
      "2. BLACKPINK\n",
      "3. EXO\n",
      "4. TWICE\n",
      "5. Red Velvet\n",
      "Relevance: \t notGrounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"KPOP 가수 5명만 말해줘\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
